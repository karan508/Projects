{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Student Name:- Karan Singh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we train a model to predict whether an email is Spam or Not Spam. After training\n",
    "the model, we apply it to a test set of 500 new emails (also labeled) and the model produces\n",
    "the following contingency table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | | True Class |  |\n",
    "| ---- | ---- | ---- | ---- |\n",
    "| |  | Spam | Not Spam |\n",
    "| Prdeicted Class | Spam | 70 | 30 |\n",
    "| | Not Spam | 70 |330|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Compute the precision of this model with respect to the Spam class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:-\n",
    "Precision with respect to SPAM = correctly predicted as SPAM / predicted as SPAM\n",
    "= 70 / (70 + 30) = 70 / 100 = 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Compute the recall of this model with respect to the Spam class [5 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:-\n",
    "Recall with respect to SPAM = # correctly predicted as SPAM / # true SPAM\n",
    "= 70 / (70 + 70) = 70 / 140 = 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) Suppose we have two users (Emily and Simon) with the following preferences\n",
    "        \n",
    "   **Emily hates seeing spam emails in her inbox! However, she doesn’t mind\n",
    "   periodically checking the “Junk” directory for genuine emails incorrectly marked\n",
    "   as spam.\n",
    "   Simon doesn’t even know where the “Junk” directory is. He would much prefer to\n",
    "   see spam emails in his inbox than to miss genuine emails without knowing!** \n",
    "#### Which user is more likely to be satisfied with this classifier? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:-\n",
    "In order_ to answer this question, let’s think about what it means to have high precision\n",
    "and low recall with respect to SPAM and, conversely, what it means to have high recall\n",
    "and low precision with respect to SPAM.\n",
    "##### High-precision and low recall with respect to SPAM: \n",
    "whatever the model classifies as\n",
    "SPAM is probably SPAM. However, many emails that are truly SPAM are misclassified\n",
    "as NOT SPAM. The user is likely to see some SPAM messages in his/her inbox, but will\n",
    "never have to go to the “junk” directory to look for genuine messages incorrectly marked\n",
    "as SPAM.\n",
    "#### High recall and low precision with respect to SPAM: \n",
    "the model filters all the SPAM\n",
    "emails, but also incorrectly classifies some genuine emails as SPAM. The user will never\n",
    "see SPAM emails in his/her inbox, but will have to periodically check the “junk”\n",
    "directory for genuine emails incorrectly marked as SPAM.\n",
    "Because the classifier achieves higher precision than recall, Simon is more likely to be\n",
    "satisfied with the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Consider the problem of binary classification using the Naive Bayes classifier. You are given two dimensional features (X1, X2) and the categorical class conditional distributions in the tables below. The entries in\n",
    "the tables correspond to P(X1 = x1|Ci) and P(X2 = x2|Ci) respectively. The two classes are equally likely.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| X1 = Class | | C1 | C2 |\n",
    "| --- | | ---- | ---- |\n",
    "|-1 |  | 0.2 | 0.3 |\n",
    "| 0 ||  0.4 | 0.6 | \n",
    "| 1 | | 0.4 | 0.1 |\n",
    "\n",
    "| X1 = Class | | C1 | C2 |\n",
    "| --- | | ---- | ---- |\n",
    "|-1 |  | 0.4 | 0.1 |\n",
    "| 0 ||  0.5 | 0.3 | \n",
    "| 1 | | 0.1 | 0.6 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given a data point (−1, 1), calculate the following posterior probabilities:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(C1|X1 = −1, X2 = 1) = Using Bayes’ Rule and conditional independence assumption of Naive Bayes\n",
    "\n",
    "$\\frac{P(X1=−1,X2=1|C1)P(C1)}{P(X1=−1,X2=1)}$ = $\\frac{P(X1=−1|C1)P(X2=1|C1)P(C1)}{P(X1=−1|C1)P(X2=1|C1)P(C1)+P(X1=−1|C2)P(X2=1|C2)P(C2)}$ = 0.1\n",
    "\n",
    "P(C2|X1 = −1, X2 = 1) = 1 − P(C1|X2 = −1, X1 = 1) = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Show that for Naive Bayes with two classes, the decision rule f(x) can be written in terms of $\\frac{log[P(y=1|x)]}{log[P(y=0|x)]}$ . Can the decision rule be formulated similarly for multiclass Naive Bayes?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No. the posterior ratio only can compare two classes. in\n",
    "multiclass NB, you could use a ratio to compare wehther, say, class 2 is more likely than\n",
    "class 5. but to compute teh argmax over all classes, you gotta iterate through all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) We have a training set that includes three features, and we’d like to predict a binary output\n",
    "variable. Here is the whole training set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| X1 | | X2 | X3 | X4 |\n",
    "| --- | | ---- | ---- |----|\n",
    "| A |  | X | P |  True |\n",
    "| A ||  X | Q | True |\n",
    "| A | | Y | P | False |\n",
    "| A |  | Y | Q | False |\n",
    "| B |  | X | P | True |\n",
    "| B |  | X | Q | False |\n",
    "| B |  | Y | P | False |\n",
    "| B |  | Y | Q | False |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we train a decision tree classifier using this training set, which feature would be considered\n",
    "at the first “branch” of the decision tree (the top node)? Please explain why**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature x2 is selected, because it is the feature that has the strongest association with the\n",
    "output variable. Formally, we can compute a “purity” measure that shows how the feature\n",
    "splits the training set into subgroups that are more homogeneous than the subgroups induced\n",
    "by the other two features. Here’s how two such purity measures can be computed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | | X1 | X2 | X3 |\n",
    "| --- | | ---- | ---- |----|\n",
    "| |  | A:2/2 | X:3/1 |  P:2/2 |\n",
    "| ||  B:1/3 | Y:0/4 | Q:1/3 |\n",
    "| Majority Sum | | 5 | 7 | 7 |\n",
    "| Information Gain | | 0.05 | 0.55 | 0.05 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will get a full score here if you say (1) that x2 is selected, and (2) that this is because x2\n",
    "best describes the output. It’s of course clearest if you explain (2) by means of a measure, but\n",
    "if you can give another clear explanation, that is also acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) What is overfitting and why is it a problem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solutions:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Oxford dictionary, overfitting is “the production of an analysis that\n",
    "corresponds too closely or exactly to a particular set of data, and may therefore fail to fit\n",
    "additional data or predict future observations reliably”. Informally, our model is too specific\n",
    "for our training set and fails to generalize well to new instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) K- Nearest Neighour Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)Should we use KNN algorithm for large datasets OR not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN works well with smaller dataset because it is a lazy learner. It needs to store all the data and then makes decision only at run time. It needs to calculate the distance of a given point with all other points. So if dataset is large, there will be a lot of processing which may adversely impact the performance of the algorithm.\n",
    "\n",
    "KNN is also very sensitive to noise in the dataset. If the dataset is large, there are chances of noise in the dataset which adversely affect the performance of KNN algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) How to choose optimal value of K in KNN Algorithm?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Square Root Method: Take square root of the number of samples in the training dataset.\n",
    "\n",
    "2. Cross Validation Method: We should also use cross validation to find out the optimal value of K in KNN. Start with K=1, run cross validation (5 to 10 fold),  measure the accuracy and keep repeating till the results become consistent.\n",
    "K=1, 2, 3… As K increases, the error usually goes down, then stabilizes, and then raises again. Pick the optimum K at the beginning of the stable zone. This is also called Elbow Method.\n",
    "\n",
    "3. Domain Knowledge also plays a vital role while choosing the optimum value of K.\n",
    "\n",
    "4. K should be an odd number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1)Which of the following is/are true about Random Forest and Gradient Boosting ensemble methods?**\n",
    "\n",
    "**1)Both methods can be used for classification task**\n",
    "\n",
    "**2)Random Forest is use for classification whereas Gradient Boosting is use for regression task**\n",
    "\n",
    "**3)Random Forest is use for regression whereas Gradient Boosting is use for Classification task**\n",
    "\n",
    "**4)Both methods can be used for regression task**\n",
    "\n",
    "**A) 1**\n",
    "\n",
    "**B) 2**\n",
    "\n",
    "**C) 3**\n",
    "\n",
    "**D) 4**\n",
    "\n",
    "**E) 1 and 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution: E**\n",
    "\n",
    "Both algorithms are design for classification as well as regression task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2)  Which of the following option is true about k-NN algorithm?**\n",
    "\n",
    "**A) It can be used for classification**\n",
    "\n",
    "**B) It can be used for regression**\n",
    "\n",
    "**C) It can be used in both classification and regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution: C**\n",
    "\n",
    "We can also use k-NN for regression problems. In this case the prediction can be based on the mean or the median of the k-most similar instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3) Let’s say, you are working with categorical feature(s) and you have not looked at the distribution of the categorical variable in the test data.\n",
    "You want to apply one hot encoding (OHE) on the categorical feature(s). What challenges you may face if you have applied OHE on a categorical variable of train dataset?**\n",
    "\n",
    "**A) All categories of categorical variable are not present in the test dataset.**\n",
    "\n",
    "**B) Frequency distribution of categories is different in train as compared to the test dataset.**\n",
    "\n",
    "**C) Train and Test always have same distribution.**\n",
    "\n",
    "**D) Both A and B**\n",
    "\n",
    "**E) None of these**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution: (D)**\n",
    "\n",
    "Both are true, The OHE will fail to encode the categories which is present in test but not in train so it could be one of the main challenges while applying OHE. The challenge given in option B is also true you need to more careful while applying OHE if frequency distribution doesn’t same in train and test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4) Imagine, you are working with “Reddit” and you want to develop a machine learning algorithm which predicts the number of views on the articles. \n",
    "Your analysis is based on features like author name, number of articles written by the same author on Reddit in past and a few other features. Which of the following evaluation metric would you choose in that case?**\n",
    "\n",
    "**1.Mean Square Error**\n",
    "\n",
    "**2.Accuracy**\n",
    "\n",
    "**3.F1 Score**\n",
    "\n",
    "**A) Only 1**\n",
    "\n",
    "**B) Only 2**\n",
    "\n",
    "**C) Only 3**\n",
    "\n",
    "**D) 1 and 3**\n",
    "\n",
    "**E) 2 and 3**\n",
    "\n",
    "**F) 1 and 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:(A)**\n",
    "\n",
    "You can think that the number of views of articles is the continuous target variable which fall under the regression problem. So, mean squared error will be used as an evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5) Which of the following can be used to impute data sets based only on information in the training set?**\n",
    "\n",
    "**A) postProcess**\n",
    "\n",
    "**B) preProcess**\n",
    "\n",
    "**C) process**\n",
    "\n",
    "**D) all of the mentioned**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solutions:- B**\n",
    "\n",
    "This can be done with K-nearest neighbors. For an arbitrary sample, the K closest neighbors are found in the training set and the value for the predictor is imputed using these values (e.g. using the mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:-\n",
    "- https://people.eecs.berkeley.edu/~jrs/189/exam/finals13.pdf\n",
    "- http://www.cse.chalmers.se/~richajo/dit866/files/DIT865_2018_mar_solution.pdf\n",
    "- http://www.data2businessinsights.in/2019/11/27/10484/\n",
    "- https://www.analyticsvidhya.com/blog/2017/09/30-questions-test-tree-based-models/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
